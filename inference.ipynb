{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dataset.dataloader import DataloaderMode, create_dataloader\n",
    "from model.model import Model\n",
    "from model.model_arch import Net_arch\n",
    "from utils.utils import get_pytorch_kobert_model\n",
    "from utils.utils import calc_metric\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "model_checkpoint_name = \"chkpt/KoBERT fine-tune with 3 FC_2022-11-20 06:06:36_1879.pt\"\n",
    "dataset_file_name = \"dataset/meta/KorQuAD_v1.0_dev.json\"\n",
    "config_file_name = \"config/job/train/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'NLP Final Project', 'working_dir': '/data/project/rw/andrew/snu/snu-nlp-2022', 'device': 'cuda', 'random_seed': None, 'start_time': None, 'num_epoch': 10, 'data': {'train_file': 'dataset/meta/KorQuAD_v1.0_train.json', 'test_file': 'dataset/meta/KorQuAD_v1.0_dev.json', 'file_format': '*.file_extension', 'divide_dataset_per_gpu': True}, 'train': {'num_workers': 4, 'batch_size': 32, 'optimizer': {'mode': 'adam', 'adam': {'lr': 5e-05, 'betas': [0.9, 0.999]}}}, 'test': {'num_workers': 4, 'batch_size': 4}, 'model': None, 'dist': {'master_addr': 'localhost', 'master_port': '12355', 'mode': 'nccl', 'gpus': 0, 'timeout': 30}, 'log': {'use_tensorboard': False, 'use_wandb': True, 'wandb_init_conf': {'name': '${name}', 'entity': 'snu-nlp', 'project': 'KorBert'}, 'summary_interval': 1, 'chkpt_interval': 1, 'chkpt_dir': 'chkpt'}, 'load': {'wandb_load_path': None, 'network_chkpt_path': None, 'strict_load': False, 'resume_state_path': None}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '%(message)s'}, 'detailed': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'detailed', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'detailed', 'filename': 'trainer.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(config_file_name)\n",
    "cfg.working_dir = os.getcwd()\n",
    "cfg.job_logging_cfg = {'version': 1, 'formatters': {'simple': {'format': '%(message)s'}, 'detailed': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'detailed', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'detailed', 'filename': 'trainer.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}\n",
    "cfg.test.batch_size = 4\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /data/project/rw/andrew/snu/snu-nlp-2022/.cache/kobert_v1.zip\n",
      "using cached model. /data/project/rw/andrew/snu/snu-nlp-2022/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "net_arch = Net_arch(cfg)\n",
    "model = Model(cfg, net_arch, None)\n",
    "model.load_network(torch.load(model_checkpoint_name, map_location=torch.device(cfg.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /data/project/rw/andrew/snu/snu-nlp-2022/.cache/kobert_v1.zip\n",
      "using cached model. /data/project/rw/andrew/snu/snu-nlp-2022/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "WARNING: 326/5774 elements exceed 512 (5.6460 %)\n"
     ]
    }
   ],
   "source": [
    "test_loader = create_dataloader(cfg, DataloaderMode.test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /data/project/rw/andrew/snu/snu-nlp-2022/.cache/kobert_v1.zip\n",
      "using cached model. /data/project/rw/andrew/snu/snu-nlp-2022/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "def get_vocab():\n",
    "    _, vocab = get_pytorch_kobert_model()\n",
    "    return vocab\n",
    "\n",
    "vocab = get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'exact_match': 0.0, 'f1': 0.0},\n",
       " {'6548850-0-0': '임종석이 여의도',\n",
       "  '6548850-0-1': '사전',\n",
       "  '6548853-0-0': '임종석이 여의도',\n",
       "  '6548853-0-1': '15분 경 서울청량리경찰서는'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_model(cfg, model, test_loader, n_batches=-1):\n",
    "    model.net.eval()\n",
    "    total_test_loss = 0\n",
    "    test_loop_len = 0\n",
    "    texts = dict()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            if n_batches > -1 and test_loop_len >= n_batches:\n",
    "                break\n",
    "            model_input, model_target, qa_id = data[:3], data[3:5], data[5]\n",
    "            output = model.inference(model_input)\n",
    "\n",
    "            # Calculate QA metrics\n",
    "            output = output.mT  # [batch, num_words, 2] -> [batch, 2, num_words]\n",
    "            output = torch.softmax(output, dim=-1)\n",
    "            # print(model_target)\n",
    "            # print(vocab.decode(model_input[0][0].tolist()))\n",
    "            # for i in output[0][0].tolist(): print(\"%.2f \" % i, end=\"\")\n",
    "            # print(\"\")\n",
    "            # for i in output[0][1].tolist(): print(\"%.2f \" % i, end=\"\")\n",
    "            # print(\"\")\n",
    "            # print(vocab.decode(model_input[0][0][24:30].tolist()))\n",
    "            pred = torch.argmax(output, dim=-1)  # [batch, 2]\n",
    "            batch_size = model_input[0].shape[0]\n",
    "            for i in range(batch_size):\n",
    "                input_text = model_input[0][i]\n",
    "                pred_start, pred_end = pred[i]\n",
    "                pred_text = input_text[pred_start : pred_end + 1].tolist()\n",
    "                decoded_text = vocab.decode(pred_text)\n",
    "                texts[qa_id[i]] = decoded_text\n",
    "\n",
    "            test_loop_len += 1\n",
    "\n",
    "        total_test_loss /= test_loop_len\n",
    "        metric = calc_metric(cfg, texts)\n",
    "    return texts, metric\n",
    "\n",
    "texts, metric = eval_model(cfg, model, test_loader, n_batches=1)\n",
    "metric, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('snu-nlp-2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0cfb3de5a9c3879f49a2d612c583a626ee4650fa633a31de482d5516f7a6ba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
