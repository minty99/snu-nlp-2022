{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dataset.dataloader import DataloaderMode, create_dataloader\n",
    "from model.model import Model\n",
    "from model.model_arch import Net_arch\n",
    "from utils.utils import calc_metric, get_multilingual_bert_tokenizer\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "model_checkpoint_name = \"chkpt/vanila BERT_2022-12-14 21:28:42_1871.pt\"\n",
    "dataset_file_name = \"dataset/meta/KorQuAD_v1.0_dev.json\"\n",
    "config_file_name = \"config/job/train/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'NLP Final Project', 'working_dir': '/data/project/rw/andrew/snu/snu-nlp-2022', 'device': 'cuda', 'random_seed': 42, 'start_time': None, 'num_epoch': 8, 'data': {'train_file': 'dataset/meta/KorQuAD_v1.0_train.json', 'test_file': 'dataset/meta/KorQuAD_v1.0_dev.json', 'file_format': '*.file_extension', 'divide_dataset_per_gpu': True}, 'train': {'num_workers': 1, 'batch_size': 32, 'optimizer': {'mode': 'adam', 'adam': {'lr': 5e-05, 'betas': [0.9, 0.999]}}, 'scheduler': {'max_lr': '${train.optimizer.adam.lr}', 'min_lr': 1e-05}}, 'test': {'num_workers': 1, 'batch_size': 512}, 'model': None, 'loss': {'divisor': 2.0, 'custom_smoothing': False, 'order_const': 0.0}, 'dist': {'master_addr': 'localhost', 'master_port': '12355', 'mode': 'nccl', 'gpus': 0, 'timeout': 30}, 'log': {'use_tensorboard': False, 'use_wandb': True, 'wandb_init_conf': {'name': '${name}', 'entity': 'snu-nlp', 'project': 'KorBert'}, 'summary_interval': 1, 'chkpt_interval': 1, 'chkpt_dir': 'chkpt'}, 'load': {'wandb_load_path': None, 'network_chkpt_path': None, 'strict_load': False, 'resume_state_path': None}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '%(message)s'}, 'detailed': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'detailed', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'detailed', 'filename': 'trainer.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(config_file_name)\n",
    "cfg.working_dir = os.getcwd()\n",
    "cfg.job_logging_cfg = {'version': 1, 'formatters': {'simple': {'format': '%(message)s'}, 'detailed': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'detailed', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'detailed', 'filename': 'trainer.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}\n",
    "cfg.test.batch_size = 512\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "net_arch = Net_arch(cfg)\n",
    "model = Model(cfg, net_arch, None)\n",
    "model.load_network(torch.load(model_checkpoint_name, map_location=torch.device(cfg.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = create_dataloader(cfg, DataloaderMode.test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_multilingual_bert_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0...\n",
      "Processing batch 1...\n",
      "Processing batch 2...\n",
      "Processing batch 3...\n",
      "Processing batch 4...\n",
      "Processing batch 5...\n",
      "Processing batch 6...\n",
      "Processing batch 7...\n",
      "Processing batch 8...\n",
      "Processing batch 9...\n",
      "Processing batch 10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 64.2362313820575, 'f1': 84.6992510938157}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_model(cfg, model, test_loader, n_batches=-1):\n",
    "    model.net.eval()\n",
    "    total_test_loss = 0\n",
    "    test_loop_len = 0\n",
    "    sep_token = tokenizer.convert_tokens_to_ids(\"[SEP]\")\n",
    "    texts = dict()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            if n_batches > -1 and test_loop_len >= n_batches:\n",
    "                break\n",
    "            print(f\"Processing batch {test_loop_len}...\")\n",
    "            model_input, model_target, qa_id = data[:3], data[3:5], data[5]\n",
    "            output = model.inference(model_input)\n",
    "\n",
    "            # Calculate QA metrics\n",
    "            batch_size = model_input[0].shape[0]\n",
    "            num_words = output.shape[1]\n",
    "            input_texts = model_input[0]\n",
    "\n",
    "            start = torch.softmax(output[:, :, 0], dim=1)  # [batch_size, num_words]\n",
    "            end = torch.softmax(output[:, :, 1], dim=1)  # [batch_size, num_words]\n",
    "            s_rep = start.unsqueeze(dim=2).repeat(1, 1, num_words)  # [batch_size, num_words, num_words]\n",
    "            e_rep = end.unsqueeze(dim=1).repeat(1, num_words, 1)  # [batch_size, num_words, num_words]\n",
    "            scores = s_rep + e_rep\n",
    "            scores = torch.triu(scores)  # [batch_size, num_words, num_words]\n",
    "\n",
    "            sep_mask = input_texts == sep_token  # [batch_size, num_words]\n",
    "            idx = torch.arange(sep_mask.shape[1], 0, -1)\n",
    "            tmp = sep_mask * idx\n",
    "            paragraph_starts = torch.argmax(tmp, 1) + 1\n",
    "            paragraph_starts = (\n",
    "                paragraph_starts.unsqueeze(dim=1).unsqueeze(dim=2).repeat(1, num_words, num_words)\n",
    "            )  # [batch_size, num_words, num_words]\n",
    "            indices1 = torch.arange(num_words).reshape(1, 1, num_words).repeat(batch_size, num_words, 1)\n",
    "            scores[indices1 < paragraph_starts] = 0\n",
    "            indices2 = torch.arange(num_words).reshape(1, num_words, 1).repeat(batch_size, 1, num_words)\n",
    "            scores[indices2 < paragraph_starts] = 0\n",
    "\n",
    "            scores = scores.reshape(batch_size, -1)\n",
    "            max_idx = torch.argmax(scores, dim=1)\n",
    "            \n",
    "            pred_start = max_idx // num_words\n",
    "            pred_end = max_idx % num_words\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_text = input_texts[i][pred_start[i] : pred_end[i] + 1].tolist()\n",
    "                decoded_text = tokenizer.decode(pred_text)\n",
    "                texts[qa_id[i]] = decoded_text\n",
    "\n",
    "            test_loop_len += 1\n",
    "\n",
    "        total_test_loss /= test_loop_len\n",
    "        metric = calc_metric(cfg, texts)\n",
    "    return texts, metric\n",
    "\n",
    "texts, metric = eval_model(cfg, model, test_loader)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = \" \".join(texts.values())\n",
    "flatten.count(\"[UNK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은? [SEP] 1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의 ( 폭력행위등처벌에관한법률위반 ) 으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일 ~ 20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    model_input, model_target, qa_id = data[:3], data[3:5], data[5]\n",
    "    decoded_text = tokenizer.decode(model_input[0][0].tolist())\n",
    "    print(decoded_text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('snu-nlp-2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0cfb3de5a9c3879f49a2d612c583a626ee4650fa633a31de482d5516f7a6ba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
